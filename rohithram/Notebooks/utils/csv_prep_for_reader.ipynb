{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import writefile_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '../../anomaly_detectors/utils/csv_prep_for_reader.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run $filename\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile_run  $filename -a\n",
    "\n",
    "\n",
    "\n",
    "def preparecsvtoread(filepath='../../dataset/sample_csv_files/alcohol-demand-log-spirits-consu.csv',\n",
    "                     filename='alcohol-demand-log-spirits-consu.csv',\n",
    "                     target_dir='../../dataset/reader_csv_files/',\n",
    "                     assetno='A1',n_rows=None,has_time=True):\n",
    "    \n",
    "    '''\n",
    "    Function which takes a filepath of csv file to read and processes it to standardise the csv file like \n",
    "    converts datetime object to epoch time format and adds assetno column to distinguish the data from different\n",
    "    sources like sensors!\n",
    "    \n",
    "    Arguments :\n",
    "        filepath: full filepath of the csv file to read from\n",
    "        filename: only filename without any paths enclosed in quotes\n",
    "        target_dir : path of the target directory in which csv file to be saved\n",
    "        assetno: Asset no of the dataset (Needs to be unique for a given dataset)\n",
    "        n_rows: Allows to read only first n_rows of the csv dataset\n",
    "        has_time: If False, then it adds time_stamp column to the dataset\n",
    "        \n",
    "    \n",
    "    Returns: \n",
    "    filepath of processed csv file which is ready to read from there and metric names( different column names)\n",
    "    present in the dataset\n",
    "    '''\n",
    "    \n",
    "    if(n_rows is not None):\n",
    "        df  = pd.read_csv(filepath,nrows=n_rows)\n",
    "    else:\n",
    "        \n",
    "        df = pd.read_csv(filepath)\n",
    "        n_rows = df.shape[0]\n",
    "        \n",
    "    df['assetno'] = assetno\n",
    "    \n",
    "    if(has_time!=True):\n",
    "        start = pd.Timestamp(\"19700807 08:30-0400\")\n",
    "        end = pd.Timestamp(\"20170807 17:30-0400\")\n",
    "        index = pd.DatetimeIndex(start=start, end=end, freq=\"10min\")[:n_rows]\n",
    "        df.insert(0,'timestamp', index) \n",
    "        df = df.dropna(axis=1, how='all')\n",
    "    else:\n",
    "        df = df.rename(columns={df.columns[0]:'timestamp'})\n",
    "    df['timestamp'] = (pd.to_datetime(df['timestamp'],infer_datetime_format=True).astype(np.int64)/(1e6)).astype(np.int64)\n",
    "\n",
    "    metric_names = df.columns[1:-1]\n",
    "    target_filepath = os.path.join(target_dir,filename)\n",
    "    df.to_csv(target_filepath,index=False)\n",
    "    return target_filepath,list(metric_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def csv_to_json(filepath):\n",
    "    df = pd.read_csv(filepath)\n",
    "    \n",
    "    return json_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
